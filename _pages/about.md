---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I‚Äôm now a fourth‚Äêyear undergraduate student in Northeastern University (Shenyang, China), and affiliated with the School of Computer Science and Engineering.

My research interests include Deep Learning(DL), Multimodal Learning, Natural Language Processing(NLP) and Information Retrieval(IR).

I am looking for a **Gap-year RA/Phd 24-Spring/Phd 24-Fall**. Here is my [CV](https://github.com/QC-LY/QC-LY.github.io/blob/main/files/lyhy-cv.pdf).

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2023</div><img src='../images/UniVL-DR.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<!-- [Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) -->
Universal Vision-Language Dense Retrieval: Learning A Unified Representation Space for Multi-Modal Retrieval, **ICLR 2023**

[[pdf](https://openreview.net/pdf?id=PQOlkgsBsik)][[code](https://github.com/OpenMatch/UniVL-DR)]

Zhenghao Liu, Chenyan Xiong, **Yuanhuiyi Lv**, Zhiyuan Liu, Ge Yu

This paper presents Universal Vision-Language Dense Retrieval (UniVL-DR), which builds a unified model for multi-modal retrieval. UniVL-DR encodes queries and multi-modality resources in an embedding space for searching candidates from different modalities.

</div>
</div>

<!-- [**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

# üíª Projects

<div class='paper-box'><div class='paper-box-image'><div><img src='../images/prompt.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<!-- [Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) -->
[Prompt Tuning For Sentiment Classification Base On Pre‚Äêtrained Language Models](https://github.com/QC-LY/Prompt-Tuning-For-Sentiment-Classification)

We explore the differences in performance among Full Fine‚Äêtuning, Bias‚Äêterm Fine‚Äêtuning and Prompt‚Äêtuning in the process of building a pre‚Äê training‚Äêbased sentiment classification model. To improve the performance of the prompt, we build a knowledge‚Äêbased verbalizer by acquiring knowledge from WordNet.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='../images/fundus.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Fundus Image Segmentation Base On U‚ÄêNet](https://github.com/QC-LY/Fundus-Image-Segmentation)

We used U‚Äênet to classify the fundus image at the pixel level, setting the pixels in the vascular region to 1 and the pixels in the non‚Äêvascular region to 0 to create a binary image that would segment the vascular region in the 2D fundus image.

</div>
</div>

# üìñ Educations
- *2019.09 - 2023.06 (now)*, <br/>Bachelor in Artificial Intelligence, Northeastern University, Shenyang, China. 

# üéñ Honors and Awards
- *2020.09* **Outstanding Students Scholarship**, Northeastern University. 
- *2021.09* **Outstanding Students Scholarship**, Northeastern University. 
- *2023.09* **Outstanding Students Scholarship**, Northeastern University.
- *2021.11* **The First Prize in China Undergraduate Mathematical Contest in Modeling**, CSIAM.

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->
